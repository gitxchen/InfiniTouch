{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data and Improve Matchings\n",
    "This scripts performs the following data cleaning actions to remove all errorneous samples which are caused by the motion capturing system (e.g., marker occlusion/reflection/etc.):\n",
    "- Removing unused columns\n",
    "- Synchronizing motion data and blobs in capacitive images as described in the paper\n",
    "- Dropping rows with missing values (e.g. marker occlusion) and samples in which the full-touch smartphone was not properly tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os    \n",
    "from datetime import datetime\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from skimage import measure\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%run py/labeling_names.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PICKLES_PATH = \"./data/pickles/\"\n",
    "CONDITION_DATA_PATH = \"./data/condition/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(s):\n",
    "    with open(\"status_PY03_2_match_improvement.txt\", \"a\") as myfile:\n",
    "        myfile.write(\"[\" + str(datetime.now()) + \"] \" + s + \"\\n\")\n",
    "    print(\"[\" + str(datetime.now()) + \"] \" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_participant_data(participant):\n",
    "    dfSynced = pd.read_pickle(PICKLES_PATH + \"raw_data_\" + participant + \".pkl\")\n",
    "    dfCondition = pd.read_csv(CONDITION_DATA_PATH + \"condition_\" + participant + \".txt\", header=None, names=[\"Timestamp\", \"Status\", \"Grip\", \"Finger\", \"Movement\"])\n",
    "    \n",
    "    dfCondition = dfCondition.dropna()\n",
    "    \n",
    "    dfCondition.Movement = dfCondition.Movement.replace('Free Movements', 0)\n",
    "    dfCondition.Movement = dfCondition.Movement.replace('Free Placements + Thumb on screen', 1)\n",
    "    dfCondition.Movement = dfCondition.Movement.replace('Swipe Gestures', 2)\n",
    "    dfCondition.Movement = dfCondition.Movement.astype(np.int)\n",
    "\n",
    "    dfCondition.Grip = dfCondition.Grip.replace('Grip 1', 1)\n",
    "    dfCondition.Grip = dfCondition.Grip.replace('Grip 2', 2)\n",
    "    dfCondition.Grip = dfCondition.Grip.replace('Grip 3', 3)\n",
    "    dfCondition.Grip = dfCondition.Grip.replace('Grip 4', 4)\n",
    "    dfCondition.Grip = dfCondition.Grip.replace('Grip 5', 5)\n",
    "    dfCondition.Grip = dfCondition.Grip.astype(np.int)\n",
    "\n",
    "    return dfSynced, dfCondition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unify_column_names(df, participant):\n",
    "    rb_replace_dict = {}\n",
    "    hand_replace_dict = {}\n",
    "    \n",
    "    for c in df.columns:\n",
    "        if (RIGID_BODY_NAMES[participant]) in c:\n",
    "            rb_replace_dict[c] = c.replace(RIGID_BODY_NAMES[participant], \"Phone\")\n",
    "\n",
    "    for c in df.columns:\n",
    "        if (HAND_MARKERSET_PREFIX[participant]) in c:\n",
    "            hand_replace_dict[c] = c.replace(HAND_MARKERSET_PREFIX[participant] + \":\", \"\")\n",
    "        \n",
    "            \n",
    "    df = df.rename(columns=rb_replace_dict)\n",
    "    df = df.rename(columns=hand_replace_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_moving_finger(df, dfCondition):\n",
    "    df['MovingFinger'] = (np.ones(len(df)) * -1).astype(int)\n",
    "    df = df.sort_values(by=\"OptiTrack_Timestamp\")\n",
    "\n",
    "    starts = np.array(dfCondition[::2].Timestamp)\n",
    "    ends = np.array(dfCondition[1::2].Timestamp)\n",
    "    fingers = np.array(dfCondition[::2].Finger.replace({'Thumb':0, 'Index':1, 'Middle':2, 'Ring':3, 'Little':4}).astype(int))\n",
    "    \n",
    "    for idx in range(len(starts)):\n",
    "        starttime = starts[idx]\n",
    "        endtime = ends[idx]\n",
    "        finger = fingers[idx]\n",
    "    \n",
    "        df.loc[(df.OptiTrack_Timestamp >= starttime) & (df.OptiTrack_Timestamp < endtime), 'MovingFinger'] = finger\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_nan_rows(df):\n",
    "    \"\"\"\n",
    "    Remove all frames in which no data about the fingernails are available\n",
    "    \"\"\"\n",
    "    return df.dropna(subset=[\"Thumb_Fn_X\", \"Index_Fn_X\", \"Middle_Fn_X\", \"Ring_Fn_X\", \"Little_Fn_X\", \"Phone_X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_errorneous_samples(df, participant):\n",
    "    # remove all points which are outside of the device\n",
    "    cleft = (-MAX_OUTOFDEVICE_DISTANCE)\n",
    "    cright = (NEXUS_5_SCREEN_WIDTH_MM + MAX_OUTOFDEVICE_DISTANCE)\n",
    "    df = df[(df.Thumb_Fn_X < cright) & (df.Thumb_Fn_X > cleft)\n",
    "            & (df.Index_Fn_X < cright) & (df.Index_Fn_X > cleft)\n",
    "            & (df.Middle_Fn_X < cright) & (df.Middle_Fn_X > cleft)\n",
    "            & (df.Ring_Fn_X < cright) & (df.Ring_Fn_X > cleft)\n",
    "            & (df.Little_Fn_X < cright) & (df.Little_Fn_X > cleft)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def errorneous_removal_heuristics(df):\n",
    "    df1 = df[[\"Phone_X_Rotation\", \"Phone_Y_Rotation\", \"Phone_Z_Rotation\", \"Phone_W_Rotation\"]]\n",
    "    x = df1[df1.columns[0]]\n",
    "    y = df1[df1.columns[1]]\n",
    "    z = df1[df1.columns[2]]\n",
    "    w = df1[df1.columns[3]]\n",
    "\n",
    "    rot_matrix = np.array([\n",
    "        [1-2*y*y-2*z*z, 2*x*y+2*w*z, 2*x*z - 2*w*y],\n",
    "        [2*x*y - 2*w*z, 1-2*x*x-2*z*z, 2*y*z+2*w*x],\n",
    "        [2*x*z+2*w*y, 2*y*z-2*w*x, 1-2*x*x-2*y*y]])\n",
    "\n",
    "    angle = np.degrees(np.arccos(np.dot((rot_matrix[:,1,:].T), [0, 1, 0])))\n",
    "    adf = pd.DataFrame(angle)\n",
    "    df2 = adf[np.logical_not(adf[0].isnull())]\n",
    "    df3 = df2[df2[0] < df2[0].mean() + df2[0].std()*4]\n",
    "    dfFinal = df.iloc[df3.index]\n",
    "    \n",
    "    return dfFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_unnecessary_columns(df):\n",
    "    # remove unnecessary columns to reduce file size\n",
    "    return df.drop(UNNECESSARY_COLUMNS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getContourBoundingBox(img):\n",
    "    contours = measure.find_contours(img, 35)\n",
    "    results = []\n",
    "    min_x, max_x, min_y, max_y = [], [], [], []\n",
    "\n",
    "    for n, contour in enumerate(contours):\n",
    "        if (len(contour) > 5):\n",
    "            r = [contour[:, 1], contour[:, 0]]\n",
    "            results.append(r)\n",
    "            min_x.append(r[0].min())\n",
    "            max_x.append(r[0].max())\n",
    "            min_y.append(r[1].min())\n",
    "            max_y.append(r[1].max())\n",
    "            \n",
    "    return min_x, max_x, min_y, max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_in_bounding_box(x, y, moving_finger, bb):\n",
    "    x = x * 1000 # convert to mm\n",
    "    y = y * 1000 # convert to mm\n",
    "    x = (15/62) * x + 2  # 62mm screen width\n",
    "    y = (27/110) * y + 2 # 110mm screen height\n",
    "\n",
    "    for i in range(len(bb[0])):\n",
    "        # move one screen width (15) + 1 left + 1 right side\n",
    "        xoffset = 17 if moving_finger == \"Thumb\" else 0\n",
    "        \n",
    "        if ((x + xoffset > bb[0][i] and x + xoffset < bb[1][i]) and (y > bb[2][i] and y < bb[3][i])):\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def improve_matching(df):\n",
    "    finger_name = {\n",
    "            -1: None,\n",
    "            0: \"Thumb\",\n",
    "            1: \"Index\",\n",
    "            2: \"Middle\",\n",
    "            3: \"Ring\",\n",
    "            4: \"Little\"\n",
    "        }\n",
    "\n",
    "    cols = [\n",
    "            \"Thumb_Fn_X\", \n",
    "            \"Thumb_Fn_Y\",\n",
    "            \"Index_Fn_X\", \n",
    "            \"Index_Fn_Y\",\n",
    "            \"Middle_Fn_X\", \n",
    "            \"Middle_Fn_Y\",\n",
    "            \"Ring_Fn_X\", \n",
    "            \"Ring_Fn_Y\",\n",
    "            \"Little_Fn_X\", \n",
    "            \"Little_Fn_Y\",\n",
    "            \"MovingFinger\",\n",
    "            \"ContourBoundingBoxes\"\n",
    "           ]\n",
    "\n",
    "    data = np.array(df[cols])\n",
    "    \n",
    "    matches = []\n",
    "    for idx in range(0, len(data)): # len(df)\n",
    "        best_matching_frame = idx #-1\n",
    "\n",
    "        if (idx - 240 >= 0):\n",
    "            prev_rows = range(idx-240, idx)\n",
    "            mov_finger = finger_name[data[idx][cols.index('MovingFinger')]]\n",
    "            boundingboxes = data[idx][cols.index(\"ContourBoundingBoxes\")]\n",
    "\n",
    "            if (idx % 1000 == 0):\n",
    "                print(\"Progress: \" + str(idx) + \" / \" + str(len(df)) + \" (\" + \"{:2.2f}\".format(idx / len(df) * 100) + \"%)\" ,end='\\r')\n",
    "\n",
    "            if (mov_finger != None):\n",
    "                trues = []\n",
    "                for j in prev_rows:\n",
    "                    x_pos = data[j][cols.index(mov_finger + \"_Fn_X\")]\n",
    "                    y_pos = data[j][cols.index(mov_finger + \"_Fn_Y\")]\n",
    "\n",
    "                    is_in = is_in_bounding_box(x_pos, y_pos, mov_finger, boundingboxes)\n",
    "                    if (is_in):\n",
    "                        trues.append(j)\n",
    "                \n",
    "                len_trues = len(trues)\n",
    "                if (len_trues > 0):\n",
    "                    best_matching_frame = trues[len_trues//2]\n",
    "                        \n",
    "        matches.append(best_matching_frame)\n",
    "        \n",
    "        \n",
    "    df['Matches'] = matches\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_matching(df):\n",
    "    right = df.drop([\"MatrixMerged\"], axis=1)\n",
    "    left = df[[\"MatrixMerged\", \"Matches\"]]\n",
    "\n",
    "    result = left.merge(right, left_on='Matches', right_index=True, how='left')\n",
    "\n",
    "    result = result.drop([\"Matches_y\", \"Matches_x\"], axis=1)\n",
    "    cols = result.columns.tolist()\n",
    "    result = result[cols[-2:] + cols[:-2]]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-13 15:06:13.828359] P5 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.828945] P21 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.829281] P20 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.829595] P11 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.829913] P3 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.830234] P6 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.830555] P19 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.830859] P16 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.831196] P14 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.831510] P13 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.832572] P8 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.832974] P9 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.833307] P18 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.833628] P2 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.833937] P10 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.834243] P22 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.834556] P4 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.834863] P12 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.835170] P17 is already available. Skipped.\n",
      "[2018-07-13 15:06:13.835495] Start reading ./data/pickles/raw_data_P15.pkl\n",
      "[2018-07-13 15:06:29.990207] P15: Unify Column Names.\n",
      "[2018-07-13 15:06:32.721979] P15: Remove unused columns.\n",
      "[2018-07-13 15:06:33.906108] P15: Add moving finger column.\n",
      "[2018-07-13 15:06:34.823492] P15: Create Contour Bounding Boxes.\n",
      "[2018-07-13 15:11:06.073329] P15: Find best matches to improve sync.\n",
      "[2018-07-13 15:23:56.102943] P15: Apply column matching.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(PICKLES_PATH):\n",
    "    if filename.endswith(\".pkl\"):\n",
    "\n",
    "        # To start from full_data (script 1), uncomment all boxes except the errorneous_samples and drop_nan_rows.\n",
    "        match = re.match(\"^raw_data_P[0-9]+.pkl\", filename)\n",
    "        if (match == None):\n",
    "            continue\n",
    "            \n",
    "        current_participant = filename.split(\".\")[0].split(\"_\")[2]\n",
    "        \n",
    "        if os.path.isfile(\"./data/pickles/corrected_data_with_bb_\" + current_participant + \".pkl\") :\n",
    "            log(current_participant + \" is already available. Skipped.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        log(\"Start reading \" + PICKLES_PATH + filename)\n",
    "        dfTemp, dfCondition = get_participant_data(current_participant)\n",
    "        \n",
    "        # Make naming of columns consistent \n",
    "        log(current_participant + \": Unify Column Names.\")\n",
    "        dfTemp = unify_column_names(dfTemp, current_participant)\n",
    "        \n",
    "        # Remove unused columns\n",
    "        log(current_participant + \": Remove unused columns.\")\n",
    "        dfTemp = remove_unnecessary_columns(dfTemp)\n",
    "        \n",
    "        # set currently moving finger by merging condition data with raw data\n",
    "        log(current_participant + \": Add moving finger column.\")\n",
    "        dfTemp = set_moving_finger(dfTemp, dfCondition)        \n",
    "        \n",
    "        # Create contours\n",
    "        log(current_participant + \": Create Contour Bounding Boxes.\")\n",
    "        contour_bbs = dfTemp.MatrixMerged.apply(lambda x : getContourBoundingBox(x))\n",
    "        dfTemp['ContourBoundingBoxes'] = contour_bbs\n",
    "        \n",
    "        # perform a better matching based on blob detection\n",
    "        log(current_participant + \": Find best matches to improve sync.\")\n",
    "        dfTemp = improve_matching(dfTemp)\n",
    "\n",
    "        # Apply matching and remove temporary columns\n",
    "        log(current_participant + \": Apply column matching.\")\n",
    "        dfTemp = apply_matching(dfTemp)\n",
    "        \n",
    "        ######\n",
    "        # Drop rows with missing values\n",
    "        dfTemp = drop_nan_rows(dfTemp)\n",
    "        \n",
    "        # remove samples in which the full-touch smartphone is not properly tracked\n",
    "        dfTemp = errorneous_removal_heuristics(dfTemp)\n",
    "\n",
    "        # Set participant ID\n",
    "        dfTemp['Participant'] = (np.ones(len(dfTemp)) * int(current_participant[1:])).astype(np.int)\n",
    "        \n",
    "        dfTemp.to_pickle(\"./data/pickles/corrected_data_with_bb_\" + current_participant + \".pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
