{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This script trains the model for estimating the finger positions as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import metrics\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PICKLE_DATA_PATH = \"./data/pickles/\"\n",
    "CONDITION_DATA_PATH = \"./data/condition/\"\n",
    "HDF5_PATH = \"./data/data.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf = h5py.File(HDF5_PATH, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6621129, 28, 32, 1) (6621129, 15) (2024775, 28, 32, 1) (2024775, 15)\n"
     ]
    }
   ],
   "source": [
    "train_x = hdf[\"train/images\"]\n",
    "train_y = hdf[\"train/labels\"]\n",
    "\n",
    "test_x = hdf[\"test/images\"]\n",
    "test_y = hdf[\"test/labels\"]\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myGenerator(set_name, batch_size):\n",
    "    \"\"\"\n",
    "    This generator returns normalized capacitive images (0..1) and the respective labels in mm.\n",
    "    \"\"\"\n",
    "    hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "\n",
    "    pImages = hdf[set_name + \"/images\"]\n",
    "    pLabels = hdf[set_name + \"/labels\"]\n",
    "\n",
    "    len_train = pImages.shape[0]\n",
    "    \n",
    "    randomBatchOrder = np.arange(len_train // batch_size)\n",
    "       \n",
    "    while True:\n",
    "        np.random.shuffle(randomBatchOrder) \n",
    "        \n",
    "        for i in range(len_train // batch_size):\n",
    "            idx = randomBatchOrder[i]\n",
    "            shuffled = shuffle(pImages[idx * batch_size: (idx+1) * batch_size], pLabels[idx * batch_size: (idx+1) * batch_size])\n",
    "            yield shuffled[0]/256, shuffled[1]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "num_output = 5 * 3 # (x,y,z) of five fingers. \n",
    "epochs = 10000 \n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 32\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "\n",
    "###########################################\n",
    "## GPU training configuration\n",
    "###########################################\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True, device_count = {'GPU' : 4})\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.5\n",
    "config.gpu_options.allocator_type = 'BFC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "13242/13242 [==============================] - 3692s 279ms/step - loss: 20.9262 - xyrmse_zrmsle: 20.9262 - val_loss: 12.4567 - val_xyrmse_zrmsle: 12.4567\n",
      "Epoch 2/10000\n",
      "13242/13242 [==============================] - 3809s 288ms/step - loss: 11.8363 - xyrmse_zrmsle: 11.8363 - val_loss: 11.3418 - val_xyrmse_zrmsle: 11.3418\n",
      "Epoch 3/10000\n",
      "13242/13242 [==============================] - 3821s 289ms/step - loss: 11.5367 - xyrmse_zrmsle: 11.5367 - val_loss: 11.1260 - val_xyrmse_zrmsle: 11.1260\n",
      "Epoch 4/10000\n",
      "13242/13242 [==============================] - 3799s 287ms/step - loss: 11.4004 - xyrmse_zrmsle: 11.4004 - val_loss: 11.0708 - val_xyrmse_zrmsle: 11.0708\n",
      "Epoch 6/10000\n",
      " 3221/13242 [======>.......................] - ETA: 40:41 - loss: 11.2912 - xyrmse_zrmsle: 11.2912"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    ###########################################\n",
    "    ## Model architecture \n",
    "    ###########################################\n",
    "    model = Sequential()\n",
    "\n",
    "    # First layer of convolution and max pooling\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = input_shape))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Second layer of convolution and max pooling\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = \"relu\", kernel_initializer=glorot_uniform()))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation = \"relu\", kernel_initializer=glorot_uniform()))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Output layer \n",
    "    model.add(Dense(num_output)) \n",
    "    \n",
    "    ###########################################\n",
    "    ## Model training \n",
    "    ###########################################    \n",
    "    def xyrmse_zrmsle(y_true, y_pred):\n",
    "        xy_true = tf.gather(y_true, [0,1,3,4,6,7,9,10,12,13], axis=1)\n",
    "        xy_pred = tf.gather(y_pred, [0,1,3,4,6,7,9,10,12,13], axis=1)\n",
    "        z_true = y_true[:,2::3]\n",
    "        z_pred = y_pred[:,2::3]\n",
    "        z_dist = z_true - z_pred\n",
    "\n",
    "        # RMSE for x and y axis\n",
    "        xy_rmse = K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "        \n",
    "        # RMSLE for z axis\n",
    "        z_rmsle = K.sqrt(K.mean(K.square((K.log(K.abs(z_dist) + 1.)/K.log(np.e))), axis=-1))\n",
    "        return xy_rmse + z_rmsle\n",
    "    \n",
    "    optimizer = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss=xyrmse_zrmsle,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[xyrmse_zrmsle])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "    \n",
    "    # Broadcast progress to the tensorboard. \n",
    "    # TODO: Replace [PATH_TO_TENSORBOARD_FOLDER] with your own TensorBoard path\n",
    "    readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "    tensorflowFolder = \"./[PATH_TO_TENSORBOARD_FOLDER]/FTSP_v2_\" + readable_timestamp\n",
    "    tfbCallback = keras.callbacks.TensorBoard(log_dir=tensorflowFolder, histogram_freq=0,  \n",
    "              write_graph=True, write_images=True)\n",
    "\n",
    "    model.fit_generator(myGenerator(\"train\", batch_size),\n",
    "                        steps_per_epoch=len(train_x) // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=myGenerator(\"test\", batch_size),\n",
    "                        validation_steps=len(test_x) // batch_size,\n",
    "                        callbacks=[tfbCallback, learning_rate_reduction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
